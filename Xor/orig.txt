Programmers at OpenAI, an artificial intelligence research company, recently taught a gaggle of intelligent artificial agents — bots — to play hide-and-seek. Not because they cared who won: The goal was to observe how competition between hiders and seekers would drive the bots to find and use digital tools. The idea is familiar to anyone who’s ever played the game in real life; it’s a kind of scaled-down arms race. When your opponent adopts a strategy that works, you have to abandon what you were doing before and find a new, better plan. It’s the rule that governs games from chess to StarCraft II; it’s also an adaptation that seems likely to confer an evolutionary advantage.
So it went with hide-and-seek. Even though the AI agents hadn’t received explicit instructions about how to play, they soon learned to run away and chase. After hundreds of millions of games, they learned to manipulate their environment to give themselves an advantage. The hiders, for example, learned to build miniature forts and barricade themselves inside; the seekers, in response, learned how to use ramps to scale the walls and find the hiders.